{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtPrTpZT0Iog"
      },
      "outputs": [],
      "source": [
        "#is_copied=0\n",
        "is_copied=1\n",
        "bandwidth=0.01\n",
        "#bandwidth=0\n",
        "#batch_size=128\n",
        "batch_size=256\n",
        "center=5\n",
        "dataset='digit'\n",
        "#dataset='fashion'\n",
        "latent_dim=8\n",
        "#latent_dim=4\n",
        "pou='indicator'\n",
        "gamma=3\n",
        "#pou='smooth'\n",
        "penalty=\"MMD\"\n",
        "#penalty=\"WASS\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59LdZEJefI_r",
        "outputId": "ee5d1822-15bb-428f-c9d5-d745c486a460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting POT\n",
            "  Downloading POT-0.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (664 kB)\n",
            "\u001b[K     |████████████████████████████████| 664 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from POT) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from POT) (1.21.6)\n",
            "Installing collected packages: POT\n",
            "Successfully installed POT-0.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install POT\n",
        "import ot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey15C-HI5lHk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math, os\n",
        "from numpy import array as matrix, arange\n",
        "from numpy import zeros, ones,empty\n",
        "import tensorflow_datasets\n",
        "import random\n",
        "import math\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "\n",
        "  \n",
        "from matplotlib import pyplot as plt\n",
        "import math, os\n",
        "from numpy import array as matrix, arange\n",
        "from numpy import zeros, ones,empty\n",
        "import tensorflow_datasets\n",
        "import random\n",
        "import math\n",
        "import sklearn\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorflow.keras import datasets, layers, models,constraints\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe8Hm3NoulL_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets, layers, models,constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Zc9maSz77h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87bb844-b0d7-4a19-c0d0-28fc821db2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "if dataset=='fashion':\n",
        " (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "if dataset=='digit':\n",
        " (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGjY1-N1xkxm"
      },
      "outputs": [],
      "source": [
        "x_train=np.reshape(x_train/255, (x_train.shape[0],784))\n",
        "x_test=np.reshape(x_test/255, (x_test.shape[0],784))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8nWZztjx6wR"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=center,batch_size=1000)\n",
        "kmeans = kmeans.fit(x_train)\n",
        "A=kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-MMoyMy3C9i"
      },
      "outputs": [],
      "source": [
        "nn=x_train.shape[0]\n",
        "gg=zeros((center,nn))\n",
        "for i in range(nn):\n",
        "  for j in range(center):\n",
        "    gg[j,i]=np.dot(np.transpose(x_train[i,:]-A[j,:]),(x_train[i,:]-A[j,:]))\n",
        "label=zeros((nn,1))\n",
        "for i in range(nn):\n",
        "  label[i,0]=np.argmin(gg[:,i])\n",
        "radius=zeros((center,1))\n",
        "for i in range(center):\n",
        "  radius[i,0]=np.max(gg[i,np.where(label[:,0]==i)])**0.5+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk5pPpmf73N-"
      },
      "outputs": [],
      "source": [
        " \n",
        "if pou=='smooth':\n",
        "  def rho(xindex,r,cindex,gg):\n",
        "    z=gg[cindex,xindex]**0.5\n",
        "    if r>=z:\n",
        "      return (r**2-z**2)**gamma\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def trho(index,xindex,gg):\n",
        "    z=0\n",
        "    for j in range(center):\n",
        "      z=z+rho(xindex,radius[j,0],j,gg)\n",
        "    return rho(xindex,radius[index,0],index,gg)/z\n",
        "  prob=zeros((center,1))\n",
        "  for j in range(center):\n",
        "    for i in  range(nn):\n",
        "      prob[j,0]=prob[j,0]+trho(j,i,gg)/nn     \n",
        "\n",
        "if pou=='indicator':\n",
        "   prob=zeros((center,1))\n",
        "   for j in range(center):\n",
        "        prob[j,0]=len(np.where(label==j)[0])/nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc4AkHTz9QZY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "nprob=empty((center,1))\n",
        "for j in range(center):\n",
        "   nprob[j,0]=round(prob[j,0]*100)\n",
        "nprob[np.argmax(nprob)]=nprob[np.argmax(nprob)]+100-sum(nprob)\n",
        "nnprob=empty((center,1))\n",
        "for j in range(center):\n",
        "   nnprob[j,0]=round(prob[j,0]*10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85pyI71pJZ-O"
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        " \n",
        "input_dim=28\n",
        "n_channel=1\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s-_4KBaJeSk"
      },
      "outputs": [],
      "source": [
        "def compute_kernel(x, y,h):\n",
        "    x_size = tf.shape(x)[0]\n",
        "    y_size = tf.shape(y)[0]\n",
        "    dim = tf.shape(x)[1]\n",
        "   \n",
        "    tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1,]))\n",
        "    tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))\n",
        "    return 2*h*tf.cast(dim, tf.float32)/(2*h*tf.cast(dim, tf.float32)+tf.reduce_sum(tf.square(tiled_x - tiled_y), axis=2))\n",
        "\n",
        "\n",
        "def compute_mmd(x, y):\n",
        "    stat=0\n",
        "    x_size = tf.shape(x)[0]\n",
        "    y_size = tf.shape(y)[0]\n",
        "   \n",
        "    for scale in [1]:\n",
        "        h=scale\n",
        "        x_kernel = compute_kernel(x, x,h)-tf.eye(x_size)\n",
        "     \n",
        "        y_kernel = compute_kernel(y, y,h)-tf.eye(y_size)\n",
        "      \n",
        "        xy_kernel = compute_kernel(x, y,h)\n",
        "       \n",
        "        stat=stat+ tf.cast(x_size/(x_size-1),'float32')*tf.reduce_mean(x_kernel)  + tf.cast(y_size/(y_size-1),'float32')*tf.reduce_mean(y_kernel)  - 2 * tf.reduce_mean(xy_kernel)\n",
        "    return stat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwCSVSRhfPqb"
      },
      "outputs": [],
      "source": [
        "def compute_wass(x,y):\n",
        "  M=(tf.reduce_sum(tf.abs(tf.expand_dims(x,1) - tf.expand_dims(y,0)), 2))\n",
        "  u1 = ot.utils.unif(x.shape[0])\n",
        "  u2 = ot.utils.unif(y.shape[0])\n",
        "  M1=M.numpy()\n",
        "  w=ot.emd(u1,u2,M1)\n",
        "  val=tf.reduce_sum(w*M)\n",
        "\n",
        "  return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTCWDJ-bJkwl"
      },
      "outputs": [],
      "source": [
        "def convert_to_display(samples):\n",
        "    cnt, height, width,depth = int(math.floor(math.sqrt(samples.shape[0]))), samples.shape[1], samples.shape[2],sample.shape[3]\n",
        "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
        "    samples = np.reshape(samples, [height, cnt, cnt, width])\n",
        "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
        "    samples = np.reshape(samples, [height*cnt, width*cnt])\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvrK7Kg1Jo4o",
        "outputId": "c943055c-9b15-473e-821b-0b8edaf60668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_cov\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 3)         30        \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 26, 26, 3)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 32)        896       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 5, 5, 64)          18496     \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 2, 2, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,278\n",
            "Trainable params: 93,278\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"encoder_linear\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                20520     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,520\n",
            "Trainable params: 20,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x=layers.Conv2D(3, 3,strides=1)(encoder_inputs)\n",
        "x = layers.LeakyReLU(0.1)(x)\n",
        "x = layers.Conv2D(32, 3,strides=2)(x)\n",
        " \n",
        "x = layers.LeakyReLU(0.1)(x)\n",
        "x = layers.Conv2D(64, 3,strides=2)(x)\n",
        " \n",
        "x = layers.LeakyReLU(0.1)(x)\n",
        "x = layers.Conv2D(128, 3,strides=2)(x)\n",
        " \n",
        "x = layers.LeakyReLU(0.1)(x)\n",
        " \n",
        "encoder_outputs = layers.Flatten()(x)\n",
        " \n",
        " \n",
        "encoder_cov = keras.Model(encoder_inputs, encoder_outputs, name=\"encoder_cov\")\n",
        "encoder_cov.summary()\n",
        "\n",
        "\n",
        "\n",
        "encoder_linear_inputs=keras.Input(shape=(512,))\n",
        "encoder_linear_outputs = layers.Dense(latent_dim*center)(encoder_linear_inputs)\n",
        "encoder_linear = keras.Model(encoder_linear_inputs, encoder_linear_outputs, name=\"encoder_linear\")\n",
        "encoder_linear.summary()\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVOWqASaKNXN",
        "outputId": "fd5145de-c968-44de-e239-b0e724b98796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder_linear\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5760)              51840     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,840\n",
            "Trainable params: 51,840\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_cov\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1152)]            0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 64)         73792     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,545\n",
            "Trainable params: 92,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "intermediate_dim=3*3*128\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "decoder_linear_outputs = layers.Dense(intermediate_dim*center, activation=\"relu\")(latent_inputs)\n",
        "decoder_linear = keras.Model(latent_inputs, decoder_linear_outputs, name=\"decoder_linear\")\n",
        "decoder_linear.summary()\n",
        "decoder_inputs= keras.Input(shape=(intermediate_dim,))\n",
        "x = layers.Reshape((3, 3, 128))(decoder_inputs)\n",
        " \n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"valid\")(x)\n",
        " \n",
        "x = layers.ReLU()(x)\n",
        "x = layers.Conv2DTranspose(32, 3, strides=2, padding=\"same\")(x)\n",
        " \n",
        "x = layers.ReLU()(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, strides=2,activation=\"tanh\", padding=\"same\")(x)\n",
        "\n",
        "decoder_cov = keras.Model(decoder_inputs, decoder_outputs, name=\"decoder_cov\")\n",
        "decoder_cov.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gnqjnbML2PN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAOTJmFiLxPn"
      },
      "outputs": [],
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder_cov,encoder_linear, decoder_cov,decoder_linear, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder_cov = encoder_cov\n",
        "        self.decoder_cov = decoder_cov\n",
        "        self.encoder_linear = encoder_linear\n",
        "        self.decoder_linear = decoder_linear\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.mmd_loss_tracker = keras.metrics.Mean(name=\"mmd_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.mmd_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if pou=='smooth':\n",
        "          data1=tf.reshape(data,(batch_size,28*28*1))\n",
        "          rhovalue=[]\n",
        "          for i in range(center):\n",
        "            a=tf.sqrt(tf.reduce_sum(tf.square(data1-tf.transpose(tf.repeat(tf.expand_dims(A[i,],-1),data.shape[0],axis=1))),axis=1))\n",
        "            rhovalue.append(tf.math.multiply(tf.cast(tf.where(radius[i,0]>=a, 1, 0),'float32'),(radius[i,0]**2-a**2)**gamma))\n",
        "          b=tf.reduce_sum(tf.stack(rhovalue),axis=0)\n",
        "          for i in range(center):\n",
        "            rhovalue[i]=rhovalue[i]/b\n",
        "          x=[]\n",
        "          batch=[]\n",
        "          for centerite in range(center):\n",
        "            kk=tf.where(tf.where(tf.random.uniform([data.shape[0]])<rhovalue[centerite],0,1)==0) \n",
        "            x.append(tf.gather_nd(data, kk))\n",
        "            batch.append(kk.shape[0])\n",
        "      \n",
        "        if pou=='indicator':\n",
        "          data1,label=data\n",
        "          x=[]\n",
        "          batch=[]\n",
        "          for centerite in range(center):\n",
        "              \n",
        "              kk=tf.where(label[:,0]==centerite)\n",
        "              x.append(tf.gather_nd(data1, kk))\n",
        "              batch.append(kk.shape[0])\n",
        "        \n",
        "        x=tf.concat(x,axis=0)\n",
        "        with tf.GradientTape() as tape:\n",
        "            meanlist=encoder_linear(encoder_cov(x))\n",
        "            meanlist=tf.split(meanlist,batch,axis=0)\n",
        "            for i in range(center):\n",
        "                    meanlist[i]=meanlist[i][:,(i*latent_dim):((i+1)*latent_dim)]\n",
        "            meanlistconcat=tf.concat(meanlist,axis=0)\n",
        "            predsini=decoder_linear(meanlistconcat)\n",
        "            predsini=tf.split(predsini,batch,axis=0)\n",
        "            for i in range(center):\n",
        "                    predsini[i]=predsini[i][:,(i*intermediate_dim):((i+1)*intermediate_dim)]\n",
        "            predsini=tf.concat(predsini,axis=0)\n",
        "            predslist=decoder_cov(predsini)\n",
        "            x=tf.split(x,batch,axis=0)\n",
        "            predslist=tf.split(predslist,batch,axis=0)\n",
        "            reconstruction_loss=0\n",
        "            for i in range(center):\n",
        "                      reconstruction_loss=reconstruction_loss+input_dim * input_dim * keras.metrics.mean_squared_error(K.flatten(x[i]), K.flatten(predslist[i]))*prob[i]\n",
        "            mmd_loss=0\n",
        "            for i in range(center):\n",
        "              if is_copied==1:\n",
        "                 meanlist[i]=tf.concat([meanlist[i],meanlist[i]],axis=0)\n",
        "             \n",
        "              add_meanlist=bandwidth*tf.random.normal(shape =[meanlist[i].shape[0], latent_dim])\n",
        "              meanlist[i]=meanlist[i]+ add_meanlist\n",
        "              if penalty==\"MMD\":\n",
        "                  mmd_loss= mmd_loss+100/center*compute_mmd(tf.random.normal(shape = [meanlist[i].shape[0], latent_dim]), meanlist[i])\n",
        "              if penalty==\"WASS\":\n",
        "                  mmd_loss= mmd_loss+10/center*compute_wass(tf.random.normal(shape = [meanlist[i].shape[0], latent_dim]), meanlist[i])\n",
        "            total_loss=K.mean(reconstruction_loss + mmd_loss)\n",
        "              \n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.mmd_loss_tracker.update_state(mmd_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"mmd_loss\": self.mmd_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1oeTzclpLrO"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "def decay_schedule(epoch, lr):\n",
        "    # decay by 0.1 every 5 epochs; use `% 1` to decay after each epoch\n",
        "    if (epoch % 30 == 0) and (epoch != 0):\n",
        "        lr = lr * 0.5\n",
        "    if (epoch % 50 == 0) and (epoch != 0):\n",
        "        lr = lr * 0.2\n",
        " \n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(decay_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz-CcmdVL9hx"
      },
      "outputs": [],
      "source": [
        "x_train=x_train.reshape(x_train.shape[0],input_dim,input_dim,n_channel)\n",
        " \n",
        "x_train=x_train[0:58880,:,:,:].astype('float32')\n",
        "label=label[0:58880,:]\n",
        "vae = VAE(encoder_cov, encoder_linear,decoder_cov,decoder_linear)\n",
        "vae.compile(optimizer=keras.optimizers.Adam(0.001),run_eagerly=True)\n",
        " \n",
        "if pou=='indicator':\n",
        "  vae.fit(x_train,label,epochs=50, batch_size=batch_size,callbacks=[lr_scheduler])\n",
        "if pou=='smooth':\n",
        " A=A.astype('float32')\n",
        " vae.fit(x_train,epochs=50, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPwpe0IERbiN"
      },
      "outputs": [],
      "source": [
        "def convert_to_display(samples):\n",
        "    cnt, height, width = int(math.floor(math.sqrt(samples.shape[0]))), samples.shape[1], samples.shape[2]\n",
        "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
        "    samples = np.reshape(samples, [height, cnt, cnt, width])\n",
        "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
        "    samples = np.reshape(samples, [height*cnt, width*cnt])\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxlIhE-WJnPn"
      },
      "source": [
        "**################################################################################################################################################################################################################################**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbbq7rB9VhDU"
      },
      "outputs": [],
      "source": [
        "###generate image####\n",
        "z_sample=[]\n",
        "k=0\n",
        "zz=np.random.normal(size=(int(np.round(nprob[k])), latent_dim)) \n",
        "z_sample.append(zz)\n",
        "for k in range(1,center):\n",
        "        zz=np.random.normal(size=(int(np.round(nprob[k])), latent_dim))\n",
        "        z_sample.append(zz)\n",
        "a=decoder_cov(decoder_linear(z_sample[0])[:,(0*intermediate_dim):((0+1)*intermediate_dim)])\n",
        "for i in range(1,center):\n",
        "   a=tf.concat([decoder_cov(decoder_linear(z_sample[i])[:,(i*intermediate_dim):((i+1)*intermediate_dim)]),a],axis=0)\n",
        "a=tf.clip_by_value(a, 0, 1, name=None)\n",
        "a=tf.random.shuffle(a) \n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.imshow(convert_to_display(a), cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute W_1 distance###\n",
        "nnprob[0]=nnprob[0]+10000-np.sum(nnprob)\n",
        "z_sample=[]\n",
        "\n",
        "for i in range(center):\n",
        "      z_sample.append(np.random.normal(size=(int(nnprob[i]), latent_dim)))\n",
        "a=decoder_cov(decoder_linear(z_sample[0])[:,(0*intermediate_dim):((0+1)*intermediate_dim)])\n",
        "for i in range(1,center):\n",
        "  a=tf.concat([decoder_cov(decoder_linear(z_sample[i])[:,(i*intermediate_dim):((i+1)*intermediate_dim)]),a],axis=0)\n",
        "x_test=np.reshape(x_test,[x_test.shape[0],28*28])\n",
        "a=a.numpy()\n",
        "a=np.reshape(a,[a.shape[0],28*28])\n",
        "u1 = ot.utils.unif(a.shape[0])\n",
        "u2 = ot.utils.unif(x_test.shape[0])\n",
        "M=ot.dist(x_test,a,metric='minkowski',p=1)\n",
        "w = ot.emd2(u2, u1, M)\n",
        " "
      ],
      "metadata": {
        "id": "HlQpL1xFSWe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHrm2Yoiz_ZG"
      },
      "outputs": [],
      "source": [
        "##compute test LL ####\n",
        "from sklearn.neighbors import KernelDensity\n",
        "nnprob[0]=nnprob[0]+10000-np.sum(nnprob)\n",
        "z_sample=[]\n",
        "for i in range(center):\n",
        "      z_sample.append(np.random.normal(size=(int(nnprob[i]), latent_dim)))\n",
        "a=decoder_cov(decoder_linear(z_sample[0])[:,(0*intermediate_dim):((0+1)*intermediate_dim)])\n",
        "for i in range(1,center):\n",
        "  a=tf.concat([decoder_cov(decoder_linear(z_sample[i])[:,(i*intermediate_dim):((i+1)*intermediate_dim)]),a],axis=0)\n",
        "x_test=np.reshape(x_test,[x_test.shape[0],28*28])\n",
        "a=a.numpy()\n",
        "a=np.reshape(a,[a.shape[0],28*28])\n",
        "kde=KernelDensity(kernel='gaussian', bandwidth=0.1).fit(a)\n",
        "print(np.mean(kde.score_samples(x_test)))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}